"""!
I couldn't find a good library to write gRPC/protobuf objects to disk so this is my own implementation of a
generalized json converter for said objects. Good for writing the objects themselves but be aware that it will
write any vectors/matrixes/images stored within the objects to disk so it may be a good idea to remove said
data before converting to json if you care about performance in your implementations.
"""
import json
import pdb
from briar.briar_grpc import briar_pb2, briar_service_pb2, briar_error_pb2
from collections import defaultdict
from google.protobuf.json_format import MessageToJson
# Protobuf generated gRPC objects contain lots of fields which don't need to be saved - this is a blacklist
# of the fields to ignore
ATTRIB_IGNORE = ['ByteSize', 'Clear', 'ClearExtension', 'ClearField', 'CopyFrom',
                 'DESCRIPTOR', 'DiscardUnknownFields', 'Extensions',
                 'FindInitializationErrors', 'FromString', 'HasExtension',
                 'HasField', 'IsInitialized', 'ListFields', 'MergeFrom',
                 'MergeFromString', 'ParseFromString', 'RegisterExtension',
                 'SerializePartialToString', 'SerializeToString',
                 'SetInParent', 'UnknownFields', 'WhichOneof',
                 '_CheckCalledFromGeneratedFile', '_SetListener',
                 '__deepcopy__', '__delattr__', '__dir__', '__doc_',
                 '_extensions_by_name', '_extensions_by_number', 'EnumTypeWrapper']

def save(obj, save_path, options=None):
    m = MessageToJson(obj)
    with open(save_path, 'w') as fp:
        fp.write(m)
def dump(obj, options=None):
    m = MessageToJson(obj)
    return m

# def save(json_obj, save_path, options=None):
#     """!
#     Save a list or dictionary containing protobuf classes to a json file

#     @param json_obj list||dict: List or dict containing data to save
#     @param save_path str: Path to the file to save

#     Returns: None
#     """
#     with open(save_path, 'w') as fp:
#         fp.write(json.dumps(json_obj, default=GrpcEncoder(options).default,
#                             sort_keys=True, indent=4))


class GrpcEncoder(json.JSONEncoder):
    """!
    Encoder class which extends the normal JSON encoder to allow the encoding of gRPC objects. Inherits from
    json.JSONEncoder
    """

    def __init__(self, options=None):
        self.options = options

    def default(self, obj):
        """!
        Json hook function to convert gRPC objects into a json-serializable object

        @param obj Any: General object to convert to a json-serializable object
        @return: Json-Serializable object
        """
        # convert bytes to a byte-string
        if isinstance(obj, bytes):
            try:
                o2 = obj.decode("ISO-8859-1")
                o = {"__class__": "bytes", "__contents__": o2}
                return o
            except Exception as e:
                print('got an exception', e)
                return {"__class__": "bytes", "__contents__": bytes()}
                # print("Exception", e)
                # print("\tObject", obj)

        # convert Briar protobuf grpc objects to a dictionary
        if getattr(obj, '__module__', None) in (briar_pb2.__name__, briar_service_pb2.__name__,
                                                briar_error_pb2.__name__):
            return proto_obj_to_dict(obj, self.options)

        if "Repeated" in str(type(obj)) and "Container" in str(type(obj)):
            return {"__class__": str(type(obj)).split("'")[1],
                    "__contents__": [i for i in obj]}

        if "MapContainer" in str(type(obj)):
            return {"__class__": str(type(obj)).split("'")[1],
                    "__contents__": dict(obj.items())}

        if "EnumTypeWrapper" in str(type(obj)):
            return None

        return json.JSONEncoder.default(self, obj)


def proto_obj_to_dict(obj, options=None):
    """!
    Takes a general gRPC/protobuf object, eliminates the unnecessary fields, and stores the data in a dict.

    Classes will be saved as dictionaries with a "__class__" attribute. This should be the full import path to
    the class within its module.

    @param obj: Any gRPC object generated by protobuf files
    @return: A dictionary representing the object
    """
    d = defaultdict(list)
    for attrib in dir(obj):
        if hasattr(obj, attrib):
            # ignore a bunch of grpc fields which aren't needed. Ignore method names too
            if (not callable(getattr(obj, attrib))
                    and (not attrib.startswith("__"))
                    and attrib not in ATTRIB_IGNORE):
                d[attrib] = getattr(obj, attrib)

            # split out a callable class name and save it as an attribute
            elif attrib == "__class__":
                split_class = str(getattr(obj, attrib)).split("'")[1].split('.')
                # ignore backend protobuf classes
                if "google" in split_class \
                        or "DescriptorMapping" in split_class \
                        or "DescriptorSequence" in split_class \
                        or "EnumTypeWrapper" in split_class:
                    continue

                d[attrib] = str(getattr(obj, attrib)).split()[-1].replace("'", '').replace('>', '')
    return d


def load(load_path, options=None):
    """!
    Load the json file at the given directory, reloading dictionaries with "__class__" fields into the specified
    objects and initializing them with values defined by key/value pairs within the dictionary

    @param load_path str: Path to the json file to load

    @return: The contents of the json file deserialized into the appropriate objects
    """
    with open(load_path, "r") as f:
        return json.loads(''.join(f.readlines()), object_hook=GrpcDecoder(options).default)


class GrpcDecoder(json.JSONDecoder):
    """!
    Object which extends the JSONDecoded to allow it to read saved gRPC files. Applied as a hook
    in the json load function. Inherits from json.JSONDecoder
    """

    def __init__(self, options):
        self.options = options

    def default(self, obj):
        """!
        Takes the given object and convert it into a gRPC object if its a dictionary
        @param obj object||dict: Dictionary which represents an object.

        @return: object
        """
        if isinstance(obj, dict) and '__class__' in obj:
            cls = obj['__class__']
            import_path = obj['__class__'].split('.')
            module_name = '.'.join(import_path[:-1])
            class_name = import_path[-1]

            # convert byte arrays which were written as strings
            if cls == "bytes":
                try:
                    return obj["__contents__"].encode("ISO-8859-1")
                except Exception as e:
                    print('Exception: ', e)
                    return bytes()

            # convert protobuf lists and dictionaries
            elif ("Repeated" in cls and "Container" in cls) or ("MapContainer" in cls):
                if ("Repeated" in cls and "Container" in cls):
                    l = list()
                    for list_item in obj['__contents__']:
                        l.append(self.default(list_item))
                    # return l
                else:  # "MapContainer" in cls
                    d = dict()
                    for k, v in obj['__contents__'].items():
                        d[k] = self.default(v)
                    # return d
                return obj['__contents__']

            # convert protobuf/grpc objects
            elif module_name in (briar_pb2.__name__, briar_service_pb2.__name__):
                return dict_to_proto_obj(obj, self.options)

        return obj


def dict_to_proto_obj(obj_dict, options=None):
    """!
    Take the object dictionary, read the dict which is saved in in the '__class__' key, and initialize it with
    values stored in the dictionary's key/value pairs

    @param obj_dict dict: A dictionary specifically containing a '__class__' key/value pair storing the full module
                     path to the object.

    @return: A gRPC object defined by '__class__'
    """
    cls_path = obj_dict['__class__'].split('.')
    module_name = cls_path[0]
    module = __import__(module_name)
    for sub_module in cls_path[1:]:
        module = getattr(module, sub_module)
    class_ref = module

    cls_instance = class_ref()
    for attrib, value in obj_dict.items():
        if attrib == '__class__':
            continue
        try:
            if not value == [] and not value == {}:
                setattr(cls_instance, attrib, value)
        except AttributeError:
            # some protobuf objects don't like direct assignment
            # try:
            cls_attrib = getattr(cls_instance, attrib)
            if "MergeFrom" in dir(cls_attrib):
                try:
                    cls_attrib.MergeFrom(value)
                except:
                    for k in value:
                        if hasattr(cls_attrib, 'get_or_create'):
                            o = cls_attrib.get_or_create(k)
                            o.CopyFrom(value[k])
            elif "CopyFrom" in dir(cls_attrib):
                cls_attrib.CopyFrom(value)
        # except Exception as e:
        #     if True:# options is not None and options.verbose:
        #         print('Warning: Could not write attribute ', attrib) #TODO: Fix durations and errors to correctly load through
        #         print(e)
    return cls_instance
